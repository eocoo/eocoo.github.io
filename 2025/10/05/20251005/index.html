<!DOCTYPE HTML>
<html lang="en">
<head>
  <meta charset="utf-8">
  
  <title>Kafka Producer（下） | Echo</title>
  <meta name="author" content="shanhm">
  
  <meta name="description" content="关于Kafka Producer的实现细节与常见问题">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="Kafka Producer（下）"/>
  <meta property="og:site_name" content="Echo"/>

  
    <meta property="og:image" content=""/>
  

  <link href="/favicon.ico" rel="icon">
  <link rel="alternate" href="/atom.xml" title="Echo" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  
<script>
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
			m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

	ga('create', 'UA-147251181-1', 'auto');
	ga('send', 'pageview');

</script>


<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head>


<body>
  <header id="header" class="inner"><script async src="//js/busuanzi.js"></script>
<div class="alignleft">
  <h1><a href="/">Echo</a></h1>
  <span style="color:#736f6f; height:20px;line-height:30px;">It's a long long way to go</span>
  <h2><font style="color: #736f6f;">articles:  115 &nbsp;&nbsp;&nbsp; views: <span id="busuanzi_value_site_uv"></span></font></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/">Home</a></li>
    
      <li><a href="/about">Abount</a></li>
    
  </ul>
  <div class="clearfix"></div>
</nav>

<div class="clearfix"></div>
</header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper"><article id="post-20251005" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time class="dt-published" datetime="2025-10-04T16:00:00.000Z" style="margin-bottom: 10px;"><a href="/2025/10/05/20251005/" style="color: #736f6f;">2025-10-05</a></time>
      
      

  
  
    <h1 class="p-name title" itemprop="headline name">
        Kafka Producer（下）
    </h1>
    
    
       <div class="title" style="padding: 5px 0px 20px 10px; color: #766;">
            ———— AutoMq原文 https://mp.weixin.qq.com/s/NSCmB77HPNsaMm4Y_TuV-g
       </div> 
    
  
  
  


<script async src="//js/busuanzi.js"></script>


   <span style="line-height:35px; height:35px; ">  </span>

   <font style="color: #999;"> words: 3.8k  &nbsp;&nbsp; views: <span id="busuanzi_value_page_pv"></span> &nbsp;&nbsp; time: 14min</font>
   
   
  
  <div class="categories">
    <a href="/categories/Kafka/">Kafka</a>
  </div>


   
   

   
   <hr style="background-color: #ddd; height:1px; border:none;" /><br>
   


    </header>
      
    <div class="e-content entry" itemprop="articleBody">
      
        <p>关于Kafka Producer的实现细节与常见问题</p>
<span id="more"></span>

<h3 id="幂等性"><a href="#幂等性" class="headerlink" title="幂等性"></a>幂等性</h3><p>在一个分布式消息系统中，各个角色均有可能发生故障。以Apache Kafka为例，Broker和Client都有可能会崩溃，Broker与Client之间的网络请求与响应都有可能丢失。</p>
<p>根据Producer处理这类故障时采取的策略，可以分为以下几种语义：</p>
<ul>
<li>至少一次（At Least Once）：当发生请求超时或者服务端错误时，Producer重复尝试发送消息直至成功。这样做可以保证每条消息都被写入Topic，但是可能会发生重复</li>
<li>至多一次（At Most Once）：在超时或报错时Producer不进行重试，每条消息仅发送一次。这样做可以避免消息重复，但也可能会导致消息丢失</li>
<li>精确一次（Exactly Once）：Producer进行适当的重试，以确保每条消息会且仅会被写入Topic 一次，既不重复，也不遗漏。Exactly Once的语义是最理想的实现，可以满足绝大多数业务场景的需求，但也是最难实现的，它需要Client与Broker之间的配合</li>
</ul>
<h4 id="开启幂等性"><a href="#开启幂等性" class="headerlink" title="开启幂等性"></a>开启幂等性</h4><p>Kafka Producer开启幂等性只需要设置几个配置项，无需修改代码</p>
<p><strong>相关配置</strong></p>
<ul>
<li>acks：当指定数量的副本收到消息后，Producer才会认为消息写入完成，默认为all</li>
</ul>
<blockquote>
<p>acks&#x3D;all：Producer会等待所有同步的（in sync）副本的响应<br>acks&#x3D;1：Producer会等待leader broker的响应<br>acks&#x3D;0：Producer不会等待任何broker的响应，消息写入网络层后即认为写入成功</p>
</blockquote>
<ul>
<li>enable.idempotence：开启幂等性，保证每条消息写入且仅被写入一次，同时保证消息按照发送顺序写入，默认为true</li>
</ul>
<blockquote>
<p>开启此配置时，需要保证max.in.flight.requests.per.connection（在收到Broker响应ack之前，最多可以发送的未完成请求数量）不大于5，retries大于0，acks设置为all     </p>
<p>Producer只能避免由自身重试策略（Producer、Broker 或网络出错）导致的消息重复，无法处理以下几种情况：<br>只保证会话级别的不重不漏，当Producer发生重启时，无法保证重启后与重启前发送的消息不重复<br>只保证Partition级别的不重不漏，不能保证向多个Partition发送的消息不重复<br>如果发送耗时超过了delivery.timeout.ms，Producer抛出TimeoutException，此时无法保证对应的消息是否已经被Broker持久化，需要上层根据情况进行处理   </p>
</blockquote>
<h4 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h4><p>为了实现幂等性，Kafka引入了以下两个概念：</p>
<ul>
<li>Producer ID（以下简称 PID）：Producer的唯一标识。PID由Idempotent Producer在首次发送消息前，请求Broker分配获得，是全局唯一的。PID仅在Producer和Broker内部使用，不会暴露给Client使用者</li>
<li>Sequence Number（以下简称 SEQ）：消息的序列号。该序列号在(PID, Partition) 维度上严格递增。事实上SEQ会存储在Record Batch的头中，作为Batch中第一条消息的SEQ，Batch中其它消息的SEQ依次递增</li>
</ul>
<p>另外还有Producer Epoch，它与PID结合才会唯一标识一个Producer，它的在不同的场景下有不同的用途：</p>
<blockquote>
<p>对于开启事务能力的Producer（配置了transactional.id），Producer Epoch同样由Broker分配。这样做可以保证，多个具有相同Transactional ID的Producer中仅会有一个生效，即Fence Producer     </p>
<p>对于没有开启事务能力的Producer，Producer Epoch则由Producer自己维护，它会在需要重置序列号（Reset SEQ）时增长，并将SEQ重置到0</p>
</blockquote>
<p>对于PID与SEQ，均会跟随消息持久化到Log中</p>
<p><img src="/img/20251005/20251005.1.png"> </p>
<h5 id="服务端"><a href="#服务端" class="headerlink" title="服务端"></a>服务端</h5><p>Broker会在内存中记录每个Producer的状态信息，包括Producer Epoch与每个Partition最新写入的5个Record Batch的元数据（包括SEQ、offset、timestamp等），用于判断Producer发送的请求是否存在重复或者遗漏</p>
<p>另外，这些状态信息也会定期进行快照，Broker在重启时会基于快照与Log中的信息恢复出这些状态信息（这里硬编码的5也是Producer配置 max.in.flight.requests.per.connection的上限）</p>
<p>当Broker收到一个Record Batch后，在进行完必要前置操作后、真正持久化到Log前，会检查该Batch上的PID、Producer Epoch与SEQ，具体地说：</p>
<ol>
<li><p>检查该Record Batch是否与本地记录的5个Record Batch一致。若是，则认为Producer出于某些原因重复发送了该Record Batch，不进行任何操作，直接返回本地记录的元数据（主要是offset）</p>
</li>
<li><p>检查之前是否记录了该PID对应的状态信息，若没有，检查SEQ是否为0</p>
</li>
</ol>
<ul>
<li>若是，则认为这是一个全新的Producer，记录该Producer相关信息，并写入Record Batch</li>
<li>若否，则报错 UnknownProducerIdException</li>
</ul>
<ol start="3">
<li>检查Producer Epoch是否与本地记录一致，若不一致，检查SEQ是否为0</li>
</ol>
<ul>
<li>若是，则认为该Producer出于某些原因重置了SEQ，更新记录，并写入Record Batch</li>
<li>若否，则报错OutOfOrderSequenceException</li>
</ul>
<ol start="4">
<li>检查SEQ是否与最近一次写入的Record Batch的SEQ连续</li>
</ol>
<ul>
<li>若是，则缓存该Record Batch的元数据，并写入</li>
<li>若否，则报错OutOfOrderSequenceException</li>
</ul>
<p>经过上述校验处理，可以确保在客户端侧，由同一个Producer向同一个Partition写入的Record Batch都是连续的（基于 SEQ），不会存在遗漏或重复</p>
<h5 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h5><p>Producer对于幂等性的处理相对更加复杂，主要有以下两个难点：</p>
<ul>
<li><p>Producer在发送时可能会发生超时，在超时时，可能存在两种可能：“Broker没有收到请求” 或 “Broker处理了请求，但Producer没有收到响应”。这就导致Producer难以确认当某个Produce请求超时时，Broker是否已经进行了持久化</p>
</li>
<li><p>Producer可能会向同一个Broker同时发送多个Produce请求，当其中一个或多个报错时，需要根据不同情况，对它们以及后续的请求采取不同的处理方式</p>
</li>
</ul>
<p><strong>基本概念</strong></p>
<ul>
<li>在途Batch（Inflight Batch）</li>
</ul>
<p>Producer会按Partition维度，记录已经发送请求但尚未收到响应的Batch；特别地，对于幂等Producer，还会额外记录每个Inflight Batch的SEQ，并按照SEQ排序</p>
<ul>
<li>未解决的Batch（Unresolved Batch）</li>
</ul>
<p>Producer在发送消息时会进行数次重试，直至总耗时超出delivery.timeout.ms。如果某个Batch发生了Delivery Timeout，则认为其为Unresolved</p>
<p>当某个Batch被标记为Unresolved时，Producer无法判断Broker是否已经持久化这个Batch，只能通过检查这个Batch的后续Batch是否被Broker持久化（或报错OutOfOrderSequenceException）：若后续Batch写入成功，则认为它之前的Unresolved Batch也已经写入完成；否则，则认为前面的Unresolved Batch没有写入完成，需要重置SEQ</p>
<ul>
<li>提升Epoch（Bump Epoch）与重置SEQ（Reset Sequence Number）</li>
</ul>
<p>当Producer遇到无法通过重试解决的问题时（例如Inflight Batch均响应完成，但仍存在Unresolved Batch时；或Broker报错UnknownProducerIdException时），会执行Bump Epoch &amp; Reset SEQ的操作</p>
<p>具体会将Producer Epoch加一，并将出错Partition的所有Inflight Batch从零开始重新编号重新发送，并清空Unresolved Batch</p>
<p><strong>发送流程</strong></p>
<ol>
<li>判断Unresolved Batches的状态</li>
</ol>
<ul>
<li>如果确认Unresolved Batch实际已写入完成，则将其从Unresolved Batches中移除</li>
<li>如果确认Unresolved Batch实际并没有写入（判断Inflight Batches是否为空），则Bump Epoch &amp; Reset SEQ</li>
</ul>
<ol start="2">
<li>检查目前该Partition能否发送新的Batch，不能发送的场景有：</li>
</ol>
<ul>
<li>存在Unresolved Batch</li>
<li>之前发生了Bump Epoch，且仍存在老的Epoch的Inflight Batch</li>
<li>之前某个Batch正在重试（也就是说，幂等Producer在重试时，Inflight始终为1）</li>
</ul>
<ol start="3">
<li><p>如果之前发生了Bump Epoch，且已经不存在老Epoch的Inflight Batch，则Reset SEQ</p>
</li>
<li><p>获取对应Partition的下一个SEQ，并设置到Batch中</p>
</li>
<li><p>将Batch加入到Inflight Batches中</p>
</li>
<li><p>检查是否存在Delivery Timeout的Batch，若存在，则将其加入到Unresolved Batches中</p>
</li>
<li><p>向Broker发送Produce请求，等待响应</p>
</li>
<li><p>收到响应后，检查Error Code</p>
</li>
</ol>
<ul>
<li>若为不可重试错误（例如AuthorizationException），则Bump Epoch &amp; Reset SEQ，并向上层报错</li>
<li>若为可重试错误（例如TimeoutException），则加入重试队列，等待下次发送。</li>
</ul>
<p>如果报错为UnknownProducerIdException，且之前没有Reset SEQ，则Bump Epoch &amp; Reset SEQ并重试；否则直接重试<br>如果报错为OutOfOrderSequenceException，且Unresolved Batch为空，或该Batch恰好为SEQ最大的Unresolved Batch的下一个，则Bump Epoch &amp; Reset SEQ并重试；否则直接重试</p>
<ol start="9">
<li>从Inflight Batches中移除，并向上层返回成功</li>
</ol>
<p><strong>关于Inflight Request上限</strong></p>
<p>Producer的配置max.in.flight.requests.per.connection存在上限5，这同时也是Broker缓存每个PID在每个Partition发送过的最新的Batch的数量。这样做的原因是，当Inflight Request数量超过Broker缓存的Batch数量时（假设 1），存在以下反例</p>
<ul>
<li><p>Producer向Broker先后发送了两个Produce Request，且这两个请求中，均包含一个发送给Partition p1的Batch，记为b1与b2，其中b1 SEQ &lt; b2 SEQ</p>
</li>
<li><p>Broker将b1 与 b2依次持久化完成（此时Broker缓存中会记录b2的元数据），但由于网络问题，Producer没有收到响应</p>
</li>
<li><p>Producer发现超时后重试，重新发送包含b1的Produce Request</p>
</li>
<li><p>Broker收到Request后发现b1 SEQ小于缓存中的b2 SEQ，可以推测出该消息为重复的，不应写入，而是直接返回offset等信息；但由于缓存中并没有b1相关元数据，Broker也就无法返回offset信息</p>
</li>
</ul>
<h5 id="其他细节"><a href="#其他细节" class="headerlink" title="其他细节"></a>其他细节</h5><ul>
<li>Producer Epoch 溢出处理</li>
</ul>
<p>当Producer Epoch溢出时（short最大为32767），Producer会将PID与Epoch重置，并向Broker请求分配一个新的PID与Epoch，并Reset SEQ</p>
<ul>
<li>SEQ 溢出处理</li>
</ul>
<p>当SEQ溢出时（int最大为2147483647），下一条消息的SEQ会轮转回0。考虑到Inflight Batch的数量与Batch中消息的数量的限制，不会发生问题</p>
<ul>
<li>UnknownProducerIdException 处理</li>
</ul>
<p>通常的报错场景：由于Log Retention限制，Broker将Log中某个Producer发送的消息均删除了，此时Broker重启，缓存中不再有该Producer的状态信息。如果此时Producer尝试接着之前的SEQ发送消息，由于Broker无法识别PID，则会报错。这种情况，Producer只需Bump Epoch并 Reset SEQ，重新发送消息即可</p>
<h5 id="场景示例"><a href="#场景示例" class="headerlink" title="场景示例"></a>场景示例</h5><p><strong>Broker没有收到请求</strong></p>
<p><img src="/img/20251005/20251005.2.png"> </p>
<p><strong>Producer没有收到响应</strong></p>
<p><img src="/img/20251005/20251005.3.png"> </p>
<h4 id="实现细节"><a href="#实现细节" class="headerlink" title="实现细节"></a>实现细节</h4><h5 id="消息压缩"><a href="#消息压缩" class="headerlink" title="消息压缩"></a>消息压缩</h5><p>Kafka Producer支持在客户端对消息进行压缩，以减少消息的网络传输成本与存储成本。可以通过Producer配置compression.type来指定压缩算法，支持的选项有none、gzip、snappy、lz4、zstd，默认为none</p>
<p>开启压缩后，可以节约网络带宽与Broker存储空间，但是会增加Producer与Broker的CPU消耗。此外，由于压缩是以Batch维度进行的，更好的攒批（更大的 Batch）会带来更好的压缩效果</p>
<p>在实现消息压缩时，会存在这样一个矛盾：只有在真正将消息压缩到Batch中之后，才能判断它实际（压缩后）占用了多大的大小；但为了不超过batch.size的限制，需要在消息写入Batch之前就判断其压缩后的大小。</p>
<p>为了解决这个问题，Kafka提出了一个自适应的压缩率估计算法：</p>
<ol>
<li><p>维护一个Map，其中记录了每个Topic上各个压缩算法的“估计压缩率”，初始值为1.0</p>
</li>
<li><p>当某个Batch写满并压缩完成后，计算其实际压缩率（压缩后大小 &#x2F; 压缩后大小）</p>
</li>
<li><p>基于这个实际压缩率调整估计压缩率</p>
</li>
</ol>
<ul>
<li>如果实际压缩率 &lt; 估计压缩率，将估计压缩率向实际压缩率靠近，最大减少0.005</li>
<li>如果实际压缩率 &gt; 估计压缩率，将估计压缩率向实际压缩率靠近，最大增加 0.05</li>
</ul>
<ol start="4">
<li>在尝试向新的Batch写入消息时，将使用新的估计压缩率 * 1.05 作为估算值</li>
</ol>
<h5 id="Batch分裂"><a href="#Batch分裂" class="headerlink" title="Batch分裂"></a>Batch分裂</h5><p>为了应对极端情况（消息可压缩性波动导致估计值大幅偏离实际值），Kafka支持了Batch分裂的逻辑。当压缩率估计值大幅低于实际值时，可能会导致在一个Batch中写入了过多的消息以至于超出了Broker或Topic的限制（message.max.bytes 或 max.message.bytes）</p>
<p>当发生这样的问题时，就需要Producer将过大的Batch拆分开并重新发送，具体流程如下：</p>
<ul>
<li><p>Producer收到MESSAGE_TOO_LARGE报错</p>
</li>
<li><p>重置前文中提到的估计压缩率至max(1.0, 该过大Batch的实际压缩率)</p>
</li>
<li><p>将该Batch解压，并将解压出的消息基于batch.size重新攒批（由于重置了估计压缩率，这会产生多个 Batch），并重新加入发送队列</p>
</li>
<li><p>如果开启了幂等性或事务性，那么为新的多个Batch设置SEQ</p>
</li>
<li><p>释放老的Batch所使用的内存</p>
</li>
</ul>
<p><strong>监控指标</strong></p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Producer暴露的metrics</span><br><span class="line">batch-size-avg、batch-size-max                  每个Batch的大小，如果开启了消息压缩，则为压缩后大小</span><br><span class="line">batch-split-rate、batch-split-total             Batch分裂的频率与次数</span><br><span class="line">bufferpool-wait-time-ns-total                   从Buffer Pool中等待分配内存的耗时</span><br><span class="line">buffer-exhausted-rate、buffer-exhausted-total   从Buffer Pool中分配内存超时的频率与次数</span><br><span class="line">compression-rate-avg                            Batch的平均压缩率</span><br><span class="line">node-&#123;node&#125;.latency                             指定Node响应Produce请求的延时（从发送请求到收到响应），包括成功与失败的所有请求</span><br><span class="line">record-error-rate、record-error-total           发送消息（而非Batch）失败的频率与数量，包括同步调用阶段失败与异步调用阶段失败</span><br><span class="line">record-queue-time-avg、record-queue-time-max    Batch从创建到发送等待的耗时</span><br><span class="line">record-send-rate、record-send-total             发送消息的频率和数量</span><br><span class="line">record-size-avg、record-size-max                每个Batch中最大的消息（压缩前）的平均大小与最大大小</span><br><span class="line">records-per-request-avg                         每个Produce请求中消息的数量</span><br><span class="line">request-latency-avg、request-latency-max        Broker响应Produce请求的延时（从发送请求到收到响应），包括成功与失败的所有请求</span><br></pre></td></tr></table></figure>

<h4 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h4><h5 id="发送超时"><a href="#发送超时" class="headerlink" title="发送超时"></a>发送超时</h5><p>Producer发送超时的可能原因有很多，例如网络问题、Broker负载过高等</p>
<ul>
<li><p>Callback耗时过长，Producer支持在发送消息时注册回调，但该回调会在Producer的sender线程中执行，如果用户编写的回调方法执行了一些耗时操作，阻塞了sender线程的话，会导致该Producer的其它消息无法被及时发送，进而超时</p>
</li>
<li><p>Callback死锁，在Callback中同步调用send方法会导致死锁。比如在Callback方法中检查是否发生错误，如果发生错误则调用prdocuer.send().get()</p>
</li>
</ul>
<h5 id="发送线程被阻塞"><a href="#发送线程被阻塞" class="headerlink" title="发送线程被阻塞"></a>发送线程被阻塞</h5><p>尽管Producer在发送消息时是异步的，但仍有一小部分操作是同步执行的。当这些同步操作出于某些原因被阻塞时，会导致调用KafkaProducer#send方法的线程也被阻塞</p>
<ul>
<li><p>刷新Metadata超时，Producer在发送消息前可能需要请求Broker刷新Topic元数据，该操作会在send的同步阶段执行。如果Broker出于某些原因无法提供服务或响应超时，会导致Producer被阻塞直至超时</p>
</li>
<li><p>Producer Buffer满，当Producer发送消息的速率过快以至于超过Broker的处理能力，或被Broker限流时，未被发送的消息会积攒在内存Buffer Pool中。当Producer Buffer被耗尽时，send方法将被阻塞，直至出现可用Buffer或超时</p>
</li>
</ul>
<p><br><strong>参考：</strong></p>

      
    </div>
	
    <footer>
      
	  
	    
	<nav id="pagination">
	  
		  <a class="alignleft prev" href="/2025/10/26/20251026/">
		    Ubuntu 24.04.3 安装 Kubernetes v1.28.2
		  </a>
	  
	  
	  
		  <a class="alignright next" href="/2025/09/18/20250918/">
		    Linux常用网络管理命令
		  </a>
	  
	  <div class="clearfix"></div>
	</nav>
	
	    
        
  
  <div class="categories">
    <a href="/categories/Kafka/">Kafka</a>
  </div>


        

         		        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




<link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
<script src="https://unpkg.com/gitalk@latest/dist/gitalk.min.js"></script>
<script src="/js/md5.min.js"></script>
<div id="gitalk-container"></div>
<script type="text/javascript">
    var gitalk = new Gitalk({
        clientID: 'd7beb7890a79c73a3e3d',
        clientSecret: '80ea1fc195ae4b80cbd65ec9f1ce68d59595af4b',
        id: md5(window.location.pathname),
        repo: 'eocoo.github.io',
        owner: 'eocoo',
        admin: 'eocoo'
    })
    gitalk.render('gitalk-container')
</script>                              



</div></div>
    <aside id="sidebar" class="alignright">
  


  

<script src="/js/jquery-3.4.1.min.js"></script>
<script type="text/javascript">
$(document).ready(function(){
    $("#os_ul").click(function(){ $("#os_li").toggle(); });
    $("#xx_ul").click(function(){ $("#xx_li").toggle(); });
});
</script>


  

  
<div class="widget catlog">
<h3 class="title">Catlog</h3>
<ul class="entry_catlog">
<ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B9%82%E7%AD%89%E6%80%A7"><span class="toc-text">幂等性</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BC%80%E5%90%AF%E5%B9%82%E7%AD%89%E6%80%A7"><span class="toc-text">开启幂等性</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86"><span class="toc-text">实现原理</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%9C%8D%E5%8A%A1%E7%AB%AF"><span class="toc-text">服务端</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%AE%A2%E6%88%B7%E7%AB%AF"><span class="toc-text">客户端</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%85%B6%E4%BB%96%E7%BB%86%E8%8A%82"><span class="toc-text">其他细节</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF%E7%A4%BA%E4%BE%8B"><span class="toc-text">场景示例</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%82"><span class="toc-text">实现细节</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%B6%88%E6%81%AF%E5%8E%8B%E7%BC%A9"><span class="toc-text">消息压缩</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Batch%E5%88%86%E8%A3%82"><span class="toc-text">Batch分裂</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98"><span class="toc-text">常见问题</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%8F%91%E9%80%81%E8%B6%85%E6%97%B6"><span class="toc-text">发送超时</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%8F%91%E9%80%81%E7%BA%BF%E7%A8%8B%E8%A2%AB%E9%98%BB%E5%A1%9E"><span class="toc-text">发送线程被阻塞</span></a></li></ol></li></ol></li></ol>
</div>




</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">

  
  
      &copy; 2017-2025 &nbsp;&nbsp; shanhm &nbsp;&nbsp; version@1.0.0 
  
  
  
  <font style="float: right">
<script>
document.addEventListener('DOMContentLoaded', function() {
  document.querySelectorAll('figure.highlight').forEach(function(figure) {
    const copyButton = document.createElement('button');
    copyButton.className = 'code-copy-btn';
    copyButton.textContent = 'copy';
    figure.style.position = 'relative';
    figure.appendChild(copyButton);
    
    copyButton.addEventListener('click', function() {
      const codeContent = getExactCodeContent(figure);
      copyToClipboard(codeContent, copyButton);
    });
  });
  
  function getExactCodeContent(figure) {
    const codeLines = [];
    
    // 遍历所有行
    const rows = figure.querySelectorAll('tr');
    rows.forEach(row => {
      const codeTd = row.querySelector('td.code');
      if (codeTd) {
        const lineContent = getTextFromElement(codeTd);
        codeLines.push(lineContent);
      }
    });
    
    return codeLines.join('\n');
  }
  
  function getTextFromElement(element) {
    // 创建临时div来获取纯文本但保持换行
    const tempDiv = document.createElement('div');
    tempDiv.innerHTML = element.innerHTML;
    
    // 处理br标签为换行
    const breaks = tempDiv.getElementsByTagName('br');
    for (let i = breaks.length - 1; i >= 0; i--) {
      const br = breaks[i];
      br.parentNode.replaceChild(document.createTextNode('\n'), br);
    }
    
    // 获取文本内容
    let text = tempDiv.textContent || tempDiv.innerText || '';
    
    // 清理但保持缩进
    text = text.replace(/\u00A0/g, ' ') // 替换&nbsp;为普通空格
               .replace(/[ \t]+\n/g, '\n') // 清理行尾空格
               .replace(/^\s+|\s+$/g, ''); // 清理行首行尾空格
    
    return text;
  }
  
  function copyToClipboard(text, button) {
    navigator.clipboard.writeText(text).then(function() {
      showCopySuccess(button);
    }).catch(function(err) {
      console.error('copy failed: ', err);
      const textArea = document.createElement('textarea');
      textArea.value = text;
      document.body.appendChild(textArea);
      textArea.select();
      document.execCommand('copy');
      document.body.removeChild(textArea);
      showCopySuccess(button);
    });
  }
  
  function showCopySuccess(button) {
    button.textContent = 'copied!';
    button.classList.add('copied');
    setTimeout(function() {
      button.textContent = 'copy';
      button.classList.remove('copied');
    }, 2000);
  }
});
</script>
</div>
<div class="clearfix"></div>
</footer>
  
<script src="/js/jquery-3.4.1.min.js"></script>

<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>




<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>
